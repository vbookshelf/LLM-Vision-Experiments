# LLM Vision Experiments
My experiments with LLM vision

<br>

## Experiments

- Exp1 - Simple python multi thread example<br>
https://github.com/vbookshelf/LLM-Vision-Experiments/tree/main/Exp1%20-%20Simple%20multi%20thread%20example

- Exp2 - Create a simple chatgpt vision js web app<br>
(This uses the Khuluma js app that included speech)<br>
https://github.com/vbookshelf/LLM-Vision-Experiments/tree/main/Exp2%20-%20Simple%20chatgpt%20vision%20js%20web%20app

- Exp3 - Simple code to use OpenCV to display an image, a video and a webcam feed<br>
https://github.com/vbookshelf/LLM-Vision-Experiments/tree/main/Exp3%20-%20use%20opencv%20to%20display%20image%20video%20webcam

- Exp4 - Basic js code examples<br>
(Display webcam feed, get image frames, run concurrent tasks)<br>
https://github.com/vbookshelf/LLM-Vision-Experiments/blob/main/Exp4%20-%20Basic%20js%20code%20examples/README.md

- Exp5 - JS app with webcam and image marker and multi agent chat setup<br>
(JS app with webcam and image marker)<br>
https://github.com/vbookshelf/LLM-Vision-Experiments/tree/main/Exp5%20-%20JS%20app%20w%20webcam%20and%20image%20marker%20w%20multi%20agent%20chat
